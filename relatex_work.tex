In previous work, we have parallelized the Direction Independent LOFAR pipeline on a High Throughput infrastructure \citep{mechev17}. While this parallelization has helped accelerate data processing for the SKSP project, creating a performance model of our software is required if we are to predict the resources taken by future jobs. This model will be particularly useful in understanding how processing parameters will affect run time.  

Performance modelling on a distributed system is an important field of study related to \Gls{Grid} computing. A good model of the performance of tasks in distributed workflows can help more efficiently schedule these jobs on a Grid environment \citep{grid_perform_model}. The performance modelling systems require knowledge of the source code and an analytical model of the slowest parts of the code \citep{semi_analytical_model}. Many systems exist to model the performance of distributed jobs \citep{barnes2008regression, semi_analytical_model,performance_prediction,Witt2018PredictivePM}, with some employing Black Box testing \citep{cross_platform_black_box, mapreduce_analysis} or tests on scientific benchmark cases \citep{synthetic_memory_prediction}. Such performance analysis does not require intimate knowledge of the software and can be applied on data obtained from processing on a Grid infrastructure.

Empirical modelling is useful in finding performance bugs in parallel code \citep{scalability_bugs} and modelling the performance of big data architectures \citep{mean_field_modeling}. The insights from these models are used to optimise the architecture of the software system or determine bottlenecks in processing. Here, we use empirical modelling to determine how the LOFAR \texttt{prefactor} performance scales with different parameters. 
